{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "385\n",
      "4\n",
      "파일 1: 835 행\n",
      "파일 2: 660 행\n",
      "파일 3: 725 행\n",
      "파일 4: 2417 행\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def process_data(file_content):\n",
    "    # DataFrame 생성\n",
    "    df = pd.read_csv(file_content, names=['TIME','BUTTON', 'X', 'Y','Z','PRESSURE_NORMAL'])\n",
    "    \n",
    "    # 연속된 0의 구간을 찾기\n",
    "    zero_segments = []\n",
    "    current_segment = []\n",
    "    k_count= 0\n",
    "    count = 0\n",
    "    #print(df['BUTTON'])\n",
    "    for i, value in enumerate(df['BUTTON']):\n",
    "        #print(i)\n",
    "        #print(type(value))\n",
    "        if value == str(0) and i >=1:\n",
    "            count += 1\n",
    "            current_segment.append(i)\n",
    "        elif i == 0:\n",
    "            continue\n",
    "        else:\n",
    "            if count >= 600 :  # 600개 이상 연속된 0인 경우\n",
    "                k_count += 1\n",
    "                zero_segments.append(current_segment)\n",
    "            count = 0\n",
    "            current_segment = []\n",
    "            \n",
    "    print(k_count)\n",
    "    print(count)\n",
    "    #print(zero_segments)\n",
    "    \n",
    "    # 분할 지점 찾기\n",
    "    split_points = []\n",
    "    for segment in zero_segments:\n",
    "        \n",
    "        split_points.extend([segment[0], segment[-1]])\n",
    "    \n",
    "    # 데이터 분할\n",
    "    result_dfs = []\n",
    "    start = 0\n",
    "\n",
    "    for i in range(0, len(split_points), 2):\n",
    "        if i+1 >= len(split_points):\n",
    "            break\n",
    "            \n",
    "        # 0이 연속된 구간을 제외한 데이터 저장\n",
    "        if start < split_points[i]:\n",
    "            segment_df = df.iloc[start:split_points[i]]\n",
    "            if not segment_df.empty:\n",
    "                result_dfs.append(segment_df)\n",
    "        \n",
    "        start = split_points[i+1] + 1\n",
    "    \n",
    "    # 마지막 구간 처리\n",
    "    if start < len(df):\n",
    "        segment_df = df.iloc[start:]\n",
    "        if not segment_df.empty:\n",
    "            result_dfs.append(segment_df)\n",
    "    \n",
    "    return result_dfs\n",
    "\n",
    "# 데이터 처리\n",
    "dfs = process_data('yyeepp (5).csv')\n",
    "print(len(dfs))\n",
    "# 결과 파일 저장\n",
    "for i, df in enumerate(dfs, 1):\n",
    "    if i ==1:\n",
    "        df = df[1:-1]\n",
    "        df.to_csv(f'C:filehome/split_data_{i}.csv', index=False)\n",
    "        print(f'파일 {i}: {len(df)} 행')\n",
    "\n",
    "    else:\n",
    "        df.to_csv(f'filehome/split_data_{i}.csv', index=False)\n",
    "        print(f'파일 {i}: {len(df)} 행')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 불러오기\n",
    "\n",
    "for i in range(5):\n",
    "    input_file_path = f'filehome/split_data_{i+1}.csv'\n",
    "    output_file_path = f\"filehome/yqp_processed_data{i+1}.csv\"\n",
    "    data = pd.read_csv(input_file_path)\n",
    "\n",
    "    # 전체 작업 수행 시간 계산\n",
    "    data['TIME_DIFF'] = data['TIME'] - (data['TIME'].iloc[0] + 1)\n",
    "    total_time = data['TIME_DIFF'].iloc[-1]\n",
    "\n",
    "    # 공중에서 움직인 시간 (BUTTON이 0일 때)\n",
    "    air_time = data[data['BUTTON'] == 0]['TIME_DIFF'].count()\n",
    "\n",
    "    # 종이 위에서 움직인 시간 (BUTTON이 1일 때)\n",
    "    paper_time = data[data['BUTTON'] == 1]['TIME_DIFF'].count()\n",
    "\n",
    "    # 시간 차분이 0인 경우를 NaN으로 처리하여 속도와 가속도를 안전하게 계산\n",
    "    data['TIME_DIFF_DELTA'] = data['TIME_DIFF'].diff().replace(0, np.nan)\n",
    "    data['DISTANCE'] = np.sqrt(data['X'].diff()**2 + data['Y'].diff()**2)\n",
    "    data['SPEED'] = data['DISTANCE'] / data['TIME_DIFF_DELTA']\n",
    "\n",
    "    # 가속도 및 가가속도 계산\n",
    "    data['ACCELERATION'] = data['SPEED'].diff() / data['TIME_DIFF_DELTA']\n",
    "    data['JERK'] = data['ACCELERATION'].diff() / data['TIME_DIFF_DELTA']\n",
    "\n",
    "    # 무한대와 NaN 값을 안전하게 처리\n",
    "    data['SPEED'] = data['SPEED'].replace([np.inf, -np.inf], np.nan)\n",
    "    data['ACCELERATION'] = data['ACCELERATION'].replace([np.inf, -np.inf], np.nan)\n",
    "    data['JERK'] = data['JERK'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # 종이 위와 공중에서의 평균 속도, 가속도, 가가속도 다시 계산\n",
    "    mean_speed_on_paper = data[data['BUTTON'] == 1]['SPEED'].mean()\n",
    "    mean_speed_in_air = data[data['BUTTON'] == 0]['SPEED'].mean()\n",
    "    mean_accel_on_paper = data[data['BUTTON'] == 1]['ACCELERATION'].mean()\n",
    "    mean_accel_in_air = data[data['BUTTON'] == 0]['ACCELERATION'].mean()\n",
    "    mean_jerk_on_paper = data[data['BUTTON'] == 1]['JERK'].mean()\n",
    "    mean_jerk_in_air = data[data['BUTTON'] == 0]['JERK'].mean()\n",
    "\n",
    "    # 압력 값의 평균 및 분산 계산\n",
    "    pressure_mean = data['PRESSURE_NORMAL'].mean()\n",
    "    pressure_variance = data['PRESSURE_NORMAL'].var()\n",
    "\n",
    "    # 수정된 GMRT 계산 함수\n",
    "    def gmrt(button_state, d=1):\n",
    "        subset = data[data['BUTTON'] == button_state]\n",
    "        n = len(subset)\n",
    "        if n <= d:  # 샘플 포인트가 비교 간격보다 적은 경우 0 반환\n",
    "            return 0\n",
    "        # 각 점의 반경 계산 (원점 또는 기준점으로부터의 거리)\n",
    "        radii = np.sqrt(subset['X']**2 + subset['Y']**2)\n",
    "        # d 간격으로 거리 차이 계산\n",
    "        distances = np.abs(radii.diff(periods=d).dropna())\n",
    "        gmrt_value = (1 / (n - d)) * distances.sum()\n",
    "        return gmrt_value\n",
    "\n",
    "    # 수정된 GMRT 값 계산\n",
    "    gmrt_on_paper = gmrt(1, d=1)  # d 값을 1로 설정 (필요에 따라 다른 값으로 조정 가능)\n",
    "    gmrt_in_air = gmrt(0, d=1)\n",
    "    mean_gmrt = (gmrt_on_paper + gmrt_in_air) / 2\n",
    "\n",
    "    # 펜이 종이에 닿은 횟수 (BUTTON이 0에서 1로 변할 때)\n",
    "    pendowns = data['BUTTON'].diff().eq(1).sum()\n",
    "\n",
    "    # X, Y 최대 확장\n",
    "    x_extension = data['X'].max()\n",
    "    y_extension = data['Y'].max()\n",
    "\n",
    "    # 결과를 요청한 순서대로 딕셔너리로 정리\n",
    "    result = {\n",
    "        'air_time': air_time,\n",
    "        'gmrt_in_air': gmrt_in_air,\n",
    "        'gmrt_on_paper': gmrt_on_paper,\n",
    "        'max_x_extension': x_extension,\n",
    "        'max_y_extension': y_extension,\n",
    "        'mean_acc_in_air': mean_accel_in_air,\n",
    "        'mean_acc_on_paper': mean_accel_on_paper,\n",
    "        'mean_gmrt': mean_gmrt,\n",
    "        'mean_jerk_in_air': mean_jerk_in_air,\n",
    "        'mean_jerk_on_paper': mean_jerk_on_paper,\n",
    "        'mean_speed_in_air': mean_speed_in_air,\n",
    "        'mean_speed_on_paper': mean_speed_on_paper,\n",
    "        'num_of_pendown': pendowns,\n",
    "        'paper_time': paper_time,\n",
    "        'pressure_mean': pressure_mean,\n",
    "        'pressure_var': pressure_variance,\n",
    "        'total_time': total_time\n",
    "    }\n",
    "\n",
    "    # 결과를 데이터프레임으로 변환 후 CSV 파일로 저장\n",
    "    result_df = pd.DataFrame([result])\n",
    "    result_df.to_csv(output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    mnum= i+1\n",
    "\n",
    "    # 데이터 로드\n",
    "    data = pd.read_csv(f'filehome/yqp_processed_data{i+1}.csv')\n",
    "    data.columns = data.columns + str(mnum)\n",
    "    # 모델과 스케일러 로드\n",
    "    rf_model = joblib.load(f'displacement_prediction_model{i+1}.joblib')\n",
    "    scaler = joblib.load(f'displacement_scaler{i+1}.joblib')\n",
    "\n",
    "    # 예측\n",
    "    new_data_scaled = scaler.transform(data)\n",
    "    predicted_disp_index1 = rf_model.predict(new_data_scaled)\n",
    "\n",
    "    # 예측값을 데이터프레임의 두 번째 열에 추가\n",
    "    # 먼저 기존 열의 리스트를 가져옴\n",
    "    columns_list = data.columns.tolist()\n",
    "    # 예측값을 데이터프레임으로 변환\n",
    "    predictions_df = pd.DataFrame(predicted_disp_index1, columns=[f'disp_index{i+1}'])\n",
    "    # 기존 데이터프레임과 예측값을 결합\n",
    "    data_with_predictions = pd.concat([\n",
    "        data.iloc[:, 0],  # 첫 번째 열\n",
    "        predictions_df,    # 예측값 (두 번째 열로 들어감)\n",
    "        data.iloc[:, 1:]  # 나머지 열들\n",
    "    ], axis=1)\n",
    "\n",
    "    # 결과를 CSV 파일로 저장\n",
    "    data_with_predictions.to_csv(f'filehome/updated_preprocessed_yyeepp_with_predictions{i+1}.csv', index=False)\n",
    "\n",
    "    # 저장 확인을 위한 출력\n",
    "    print(\"예측값이 추가된 데이터 미리보기:\")\n",
    "    print(data_with_predictions.head())\n",
    "    print(\"\\n컬럼 순서 확인:\")\n",
    "    print(data_with_predictions.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def merge_csv_files_horizontally():\n",
    "    # 분할된 CSV 파일들을 찾습니다\n",
    "    # csv_files = sorted(glob.glob('split_data_*.csv'), \n",
    "    #                   key=lambda x: int(x.split('_')[2].split('.')[0]))\n",
    "    csv_files = ['filehome/updated_preprocessed_yyeepp_with_predictions1.csv','filehome/updated_preprocessed_yyeepp_with_predictions2.csv','filehome/updated_preprocessed_yyeepp_with_predictions3.csv','filehome/updated_preprocessed_yyeepp_with_predictions4.csv','filehome/updated_preprocessed_yyeepp_with_predictions5.csv']\n",
    "    \n",
    "    # 각 파일의 데이터를 저장할 리스트\n",
    "    dfs = []\n",
    "    \n",
    "    # 각 CSV 파일을 읽어옵니다\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(file)\n",
    "        \n",
    "        # 파일 이름 형식을 확인하고, 올바를 경우에만 처리\n",
    "        try:\n",
    "            file_num = file.split('_')[2].split('.')[0]\n",
    "        except IndexError:\n",
    "            print(f\"파일 이름 형식이 올바르지 않습니다: {file}\")\n",
    "            continue\n",
    "        \n",
    "        # 컬럼 이름을 파일 번호를 포함하도록 변경\n",
    "        new_columns = {col: f'{col}_{file_num}' for col in df.columns}\n",
    "        df = df.rename(columns=new_columns)\n",
    "        \n",
    "        dfs.append(df)\n",
    "    \n",
    "    # 모든 데이터프레임의 행 수를 가장 긴 데이터프레임에 맞춤\n",
    "    max_rows = max(len(df) for df in dfs)\n",
    "    for i in range(len(dfs)):\n",
    "        if len(dfs[i]) < max_rows:\n",
    "            # 부족한 행을 NaN으로 채웁니다\n",
    "            dfs[i] = dfs[i].reindex(range(max_rows))\n",
    "    \n",
    "    # 데이터프레임들을 수평으로 연결\n",
    "    result = pd.concat(dfs, axis=1)\n",
    "    \n",
    "    # 결과를 새로운 CSV 파일로 저장\n",
    "    result.to_csv('filehome/merged_data.csv', index=False)\n",
    "    print(f'병합된 파일이 생성되었습니다. 총 {len(result)} 행, {len(result.columns)} 열')\n",
    "    \n",
    "    return result\n",
    "\n",
    "# 함수 실행\n",
    "merged_df = merge_csv_files_horizontally()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = joblib.load(f'BernoulliNB_best (1).joblib')\n",
    "X_1 = pd.read_csv('filehome/merged_data.csv')\n",
    "y_pred = loaded_model.predict(X_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
